# Goolge Text-to-Speech を試す

※ この記事は、
[クリエイティブ・コモンズ・表示・継承ライセンス3.0](http://creativecommons.org/licenses/by-sa/3.0/)
のもとで公表されたウィキペディアの項目
「[ディープラーニング - Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0)」
を素材として二次利用しています。

シンプルにテキストを音声にしたい、というモチベーションからgTTS（Google Text-to-Speech）を試してみた。
Web環境を用意して、gTTSをインストールすればOK。

```shell
$ pip install gTTS
```

[ディープラーニング - Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0)
のテキストを音声変換するテストコードを書いてみた。

```python
from gtts import gTTS

def main():
	txt_01 = """
	ディープラーニングまたは深層学習とは、対象の全体像から細部までの各々の粒度の概念を階層構造として関連させて学習する手法のことである。
	深層学習として最も普及した手法は、多層の人工ニューラルネットワークによる機械学習手法である。
	多層ニューラルネットワークについては、ジェフリー・ヒントンの研究チームが2006年に考案したスタックドオートエンコーダが直接の起源となった。
	"""

	txt_02 = """
	要素技術としてはバックプロパゲーションなど、20世紀のうちに開発されていたものの、4層以上の深層ニューラルネットについて、
	局所最適解や勾配消失などの技術的な問題によって十分学習させられず、性能も芳しくなかった。
	しかし、21世紀に入って、スタックドオートエンコーダを始めとするヒントンらによる多層ニューラルネットワークの学習の研究や、
	学習に必要な計算機の能力向上、および、インターネットの発展による学習データの流通により、十分に学習させられるようになった。
	その結果、音声・画像・自然言語を対象とする諸問題に対し、他の手法を圧倒する高い性能を示し、2010年代に普及した。
	学界では更に抽象化された数学的概念によるディープラーニングが研究されている。
	"""

	txt_03 = """
	ディープラーニングは、学習に用いる具体的な数学的概念はどうであれ、対象の全体像から細部までの各々の粒度の概念を階層構造として関連させて学習する手法を指す。
	21世紀に入って、オートエンコーダを始めとするジェフリー・ヒントンらによる多層ニューラルネットワークによる学習の研究や、学習に必要な計算機の能力向上、
	および、インターネットの発展による学習データの流通により、多層ニューラルネットによる手法が最初に確立された。
	その結果、音声・画像・自然言語を対象とする諸問題に対し、他の手法を圧倒する高い性能を示し、2010年代に普及した。
	結果として多層の人工ニューラルネットワークによる機械学習手法が広く知られるようになったが、ニューラルネットワーク以外でも深層学習は構成可能であり、
	現在はニューラルネットワークよりも抽象的な深層学習の数学的概念が模索されている最中にある。
	ビジネスの現場では多層ニューラルネットワークの応用が盛んであり、「ディープラーニング=ニューラルネットワーク」などと解釈される事が多いが、
	学界ではニューラルネットワーク以外の手法も含めた抽象的な概念として説明される。
	"""

	t2s(txt_01, "audio_001.mp3")
	t2s(txt_01+txt_02, "audio_002.mp3")
	t2s(txt_01+txt_02+txt_03, "audio_003.mp3")


def t2s(txt, audio_file_name):
	print('len(text):', len(txt))
	tts = gTTS(text=txt, lang='ja')
	tts.save(audio_file_name)
	print(f"Saved {audio_file_name}")
	print('')


if __name__ == "__main__":
	main()
```

コア部分はt2s()。
テキストと音声ファイル名を渡すだけ。

音声は女性の声で多少の癖はあるが聞きやすい方だと思う。
ただし、話す速度はもっと速くてもいいかな、というレベル。
[gTTSのドキュメント](https://gtts.readthedocs.io/en/latest/module.html)
を見たけど、`slow`パラメーターはあるが、`fast`というパラメーターはなかった。
なので、速くしたいなら自分で調整する処理を実装しないといけない。

あと制限については
[Google Cloud Text-to-Speechの割り当てと上限](https://cloud.google.com/text-to-speech/quotas)
に書いてあった。
ただし、Cloudの仕様なので、gTTSと同じとは限らないが、無料ならまあ十分と言える仕様である。
１分あたりのリクエスト数は1,000回なので、リクエストを数回叩けば、数万文字を音声にできるので、
この辺も自分で音声を繋げる処理を書けばなんとかなりそう。

|音声合成の上限|値|
|:--|--:|
|１リクエストあたりの合計文字数|5,000|

|上限のタイプ|使用量上限|
|:--|--:|
|1 分あたりのリクエスト数|1,000|
|1 分あたりの文字数|500,000|

上記のコードでは３種類の文字数のリクエストを投げているが、
いずれの文字数も問題なく10秒ほどで処理できていた。

```shell
$ python main.py 
len(text): 190
Saved audio_001.mp3

len(text): 526
Saved audio_002.mp3

len(text): 1033
Saved audio_003.mp3
```

## 参考文献
- [Python テキストを日本語音声で読み上げる「gTTS」](https://hk29.hatenablog.jp/entry/2020/01/27/000230)
- [ディープラーニング - Wikipedia](https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0)
- [割り当てと上限 - Cloud Text-to-Speech](https://cloud.google.com/text-to-speech/quotas)


